---
layout: default
title: "ElasticSearch 零基础入门（1）：基本概念、集群模式、查询语法和聚合语法"
author: 李佶澳
date: "2020-09-26 17:12:42 +0800"
last_modified_at: "2020-09-26 17:12:42 +0800"
categories: 项目
cover: 
tags:  Elasticsearch
keywords: Elasticsearch,es
description: "Elasticsearch 的基本概念和基本使用方法，Index、Mapping 和 Document 概念和查询语句"
---

## 目录

* auto-gen TOC:
{:toc}

## 说明

Elasticsearch 是一个准实时的分布式搜索分析引擎，提供索引、搜索和分析功能。 Logstash、xxBeats 是配套的数据导入工具，Kibana 提供了可视化页面。

**学习资料：** [es官网文档][21]


## 基本概念：Document、Index 和 Mapping

**Document**：一份序列化成 json 格式的文档数据，它由多个 filed 组成，每个 field 是一个 key-value。

**Index**： es 中的 Document 的组织单位，每个 Document 都隶属一个 Index。

**Mapping**： index 中记录 Document 的每个 filed 的数值类型。

与关系型数据库类比：

```
                   关系型数据库                     ES  
----------------------------------------------------------------------------
管理的数据单元     包含多个列的关系型行记录        包含多个k-v filed 的json 字符串
数据的组织单位     数据表                          Index 索引
数据类型描述       建表语句                        Index 的 Mapping
```

Document 的每个 field 可以使用不同的数据类型，es 根据 field 的类型使用不同的索引方式，例如：

1. text fields 存储在倒排索引中
2. numeric 和 geo 存储在 BKD tree 中

Mapping 可以手动创建，或者启用 dynamic mapping， 让 es 自动添加并推断 filed 的数据类型。

ES 的特点：

1. 文档数据（Document）写入后会在 1s 之内完成索引、可被搜索
2. 为 text 类型的 filed 建立「倒排索引/ inverted index」，支持快速的全文搜索


## 快速上手

Es 检查运行状态：

```sh
curl http://127.0.0.1:9200
```

### 创建 Index 

创建 Index 并设置 Mapping：

```sh
PUT /my-index-000001?pretty
{
  "mappings": {
    "properties": {
      "age":    { "type": "integer" },  
      "email":  { "type": "keyword"  }, 
      "name":   { "type": "text"  }     
    }
  }
}
```

PUT 上传的内容就是 Mapping，age、email、name 是 Document 中的 filed 名称，type 是 filed 的数值类型。

### 查看 Index 

查看 es 中所有 index：

```sh
GET /_cat/indices?v

health status index                          uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   .kibana-event-log-7.9.2-000001 BXulL2qmTTq2FYYOYdNqbQ   1   0          1            0      5.5kb          5.5kb
green  open   .apm-custom-link               CS8LkfBvRKGdSXjI0ky6tw   1   0          0            0       208b           208b
green  open   .kibana_task_manager_1         569Jhi3NS8etY8pYF4jxvg   1   0          6          267    136.2kb        136.2kb
green  open   kibana_sample_data_ecommerce   _6pu_ggDQCSLwL9jvrA-Fg   1   0       4675            0      4.7mb          4.7mb
green  open   .apm-agent-configuration       t9t6VR2KQi-YDewFQjI0Fw   1   0          0            0       208b           208b
green  open   .kibana_1                      pEI_2VXrTRagNq_fyWd5eg   1   0         75            1     12.6mb         12.6mb
yellow open   my-index-000001                6mmUoVrASWSTBWQjKDicqg   1   1          0            0       208b           208b
```

查看 Index  my-index-000001 的 Mapping：

```sh
GET  /my-index-000001/_mapping

{
  "my-index-000001" : {
    "mappings" : {
      "properties" : {
        "age" : {
          "type" : "integer"
        },
        "email" : {
          "type" : "keyword"
        },
        "name" : {
          "type" : "text"
        }
      }
    }
  }
}

```

### 写入 Document

`_doc` 是 ES 定义的接口路径，`1` 是要写入的 Document 的 id，Body 是 Document 内容：

```sh
PUT /my-index-000001/_doc/1
{
      "age":    11,  
      "email":  "xiaomang@mail.com", 
      "name":   "小王"   
}
```

### 查询 Document：通过 ID 查询

查询 ID 为 1 的 Document：

```sh
GET  /my-index-000001/_doc/1

{
  "_index" : "my-index-000001",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 1,
  "_seq_no" : 0,
  "_primary_term" : 1,
  "found" : true,
  "_source" : {
    "age" : 11,
    "email" : "xiaomang@mail.com",
    "name" : "小王"
  }
}
```

返回的结果中带 `_` 前缀 filed 是 Document 的 Metadata fileds，详情查看 ES 支持的 [Metadata fields][8]，后面的「Document Metadata 」章节专门介绍。

index 相关的 metadata fields：

```
_index: 文档所属的index
_type：文档 map 类型
_id：文档 id
```

index 相关的 metadata fields：

### 查询 Document：field 数值匹配查找

查找年龄为 11 的 Document，使用 query 的 term 语句：

```sh
GET /my-index-000001/_search
{
  "query": {
    "term": {
      "age": 11
    }
  }
}
```

数值匹配查找的结果是列表，hits.hits 是符合查询条件的文档列表，hits 中其它字段是对查询结果的说明：

```json
{
  "took" : 0,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 1,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "my-index-000001",
        "_type" : "_doc",
        "_id" : "1",
        "_score" : 1.0,
        "_source" : {
          "age" : 11,
          "email" : "xiaomang@mail.com",
          "name" : "小王"
        }
      }
    ]
  }
}
```


### 删除 Document 

```sh
DELETE /my-index-000001/_doc/1
{
  "_index" : "my-index-000001",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 6,
  "result" : "deleted",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 5,
  "_primary_term" : 1
}
```

文档已删除：

```sh
GET /my-index-000001/_doc/1
{
  "_index" : "my-index-000001",
  "_type" : "_doc",
  "_id" : "1",
  "found" : false
}
```

## 集群模式

ES 支持集群模式部署 [Set up a cluster for high availability][30]，支持数据多副本备份。

### 节点角色

ES 支持的功能较多（譬如机器学习），为了更好的支持这些功能，es 定义了多种节点角色，一个节点可以同时担任多种角色，默认具有以下角色：

1. master
2. data
3. data_content
4. data_hot
5. data_warm
6. data_cold
7. data_frozen
8. ingest
9. ml
10. remote_cluster_client
11. transform

ES 集群中的节点大致可以分为`管理节点`、`数据节点`和`任务节点`。

**管理节点** ：

1. 角色配置为 master，能够参与 leader 投票、可以被选为 leader 的节点
2. 被选为 leader 的节点负责集群的管理工作
3. 如果同时配置了 voting_only 角色，该节点只参与选举投票，不做候选人

**数据节点**：

1. 角色配置为 data，负责存储数据和提供数据查询、聚合处理的节点
2. 数据节点可以进一步细分：data_content，data_hot，data_warm，data_cold，data_frozen
3. data_content: 存放 document 数据
4. data_hot： 存放刚写入的时间序列数据（热点数据），要能够快速读写
5. data_warm：不再经常更新、低频查询的数据
6. data_cold：极少访问的只读数据
7. data_frozen：缓存从快照中查询出的数据，如果不存在从快照读取后缓存，

**任务节点** 类型较多，每个角色负责专门的任务：

1. []： 角色为空，coordinating node，没有任何角色，只负责将收到的请求转发到其它节点
2. ingest：承担 pipeline 处理任务的节点
3. remote_cluster_client：跨集群操作时，与其它机器进行通信的节点
4. ml：执行机器学习任务和处理机器学习 api 的节点，通常建议同时配置角色 remote_cluster_client
5. transform：数据处理节点，对文档数据进行再次加工，通常建议同时配置角色 remote_cluster_client

### 数据存储方式

[Scalability and resilience: clusters, nodes, and shards][32]

Index 是文档的组织单位，每个 index 对应多个 shard（数据分片），每个 shard 是一个小的 index。

Index 中的文档被分散到一组 shard 上存储，这些 shard 可以分布在不同的机器上。

Shard 分为 `primary shard` 和 `replica shard`。

**primary shards**： 和其它 primariy shard 一起存储 index 中全部文档，每个文档只会被 primariy shard 存储一次。primariy shard 的目的是用水平扩展方式提高存储容量。

**replica shards**： 每个 primariy shard 对应的备份。replica shard 的目的是数据备份，防丢失。

> primariy shards 的数量在 index 创建时固定，replica shards 数量可以随时更改。

### shards 数量建议

primariy shards 的数量如果太多：

1. 每个 shard 上存储的数据越少，管理开销会增加
2. 单个 shard 的查询虽然加快，但是用户的一次查询可能要被分发到更多 shard 上执行，整体变慢

primariy shards 的数量如果太少：

1. 单个 shard 过大，es 进行数据迁移的时间增加

推荐做法：

1. 单个 shard 的大小控制在 几GB～几十GB，如果是时间序列数据，单个 Shard 建议 20GB～40GB

更多建议：[testing with your own data and queries][33]

### 跨集群备份

ES 支持跨集群备份，可以创建另外一个集群做为备集群。主集群负责写操作，副集群平时只读，在主集群故障接替主集群，见 [Cross-cluster replication][34]。

容灾方案参考：[Designing for resilience][35]

### 正确性与一致性等级

[Reading and Writing documents][36] 介绍了 ES 的读写行为。

ES 数据备份使用的是 `primary-backup` 模型：

1. primary shard 承接写操作，负责将改动同步到 replica shards
2. primary shard 和 replica shards 一起承接读操作

primay-backup 模型参考 [PacificA: Replication in Log-Based Distributed Storage Systems][37]。

**`ES 的正确性等级较低`**，可能读到脏数据：

1. 读到未确认的数据：primary shard 完成本地写之后，数据就对外可见，此时这些数据被没有同步到 replia shards
2. 读到过时的脏数据：primary shard 失去了 primary 身份而不自知，继续执行无法同步到 replia shard 的本地写，发送到该 primary shard 的读请求读到过时的脏数据

ES的一致性等级应该是 **「[会话单调写一致](/编程/2021/10/11/geek-fenbushi-jr.html#单会话单调写一致)」**，等级较低，只能保证每个节点上的数据写入顺序相同。

#### 写操作过程

**写操作**：

1. coordinating stage：根据文档 ID 找到对应的 primary shard，将请求转发过去，
2. primary stage：primary shard 完成本地操作后，将操作同步到 master 节点维护的 in-sync 队列中的 replica shards， 所有 replica shards 操作完成后 ，primary shard 向客户端返回成功
3. replica stage：replica shards 本地回放 primary shard 上的操作，更新本地数据

coordinating stage、primary stage、replica stage，三个阶段串行执行，每个阶段都要下个阶段完成后，才返回完成。 

**异常处理**：

1. 如果 primary shard 故障，当前写操作等待 master 节点选出新的 primary shard （默认等待 1 分钟），然后将请求转发给新选出的 primary shard
2. 如果 primary shard 发起同步时，replica shard 无回应，primary shard 通知 master 将问题 replica shard 从 in-sync 队列移除。master 回应后，primary shard 即回应客户端，与此同时，master 新建了一个 replica shard 进行数据同步
3. 如果在执行期间 primary shard 失去了 primary 身份而不自知（断网隔离/长GC导致），向 replica shard 发送的同步请求被拒绝后，primary shard 向 mater 请求最新的 primary shard，将请求转发给新的 primary shard

#### 读操作过程

**读操作**：

读操作有两类，一类是通过 ID 直接读，一类是条件查询。收到读请求的节点为 coordinating node，es 的所有节点都具备 coordinating 能力。
coordinating node 对读请求的处理过程：
 
1. 解析请求内容，找出需要的 replica groups（replica group：primary shard 和它的 replica shards）
2. 从每个 replica group 中选出一个 shard，可能是 primary shard 也可能是  replica shard
3. 将请求分拆后发送给选出的 shards
4. 汇总 shards 返回的数据，整理后返回客户端

从 replica group 中选 shard 的时候，使用轮询法或者 [Adaptive replica selection][38]。

**异常处理**：

1. 如果 shard 未响应，coordinating node 选择下一个 shard，直到成功或 shard 用尽

一次读请求涉及多个 shard 时，如果部分成功部分失败，`Search`、`Multi Search`、`Bulk`、`Multi Get` 操作会返回成功部分的数据，返回码是 200 ok，即`可能返回不完整的数据`。客户端需要从返回的响应头中获取失败 shard 的信息。

## 更多操作

### Index 的自动创建 

ES 支持在写入的 document 的时候自动创建 index，不需要提前创建 index：

```sh
PUT /new-index-000001/_doc/1
{
      "age":    11,  
      "email":  "xiaomang@mail.com", 
      "name":   "小王"   
}

```

查看：

```
GET /new-index-000001/
```

### 批量写入Document

```sh
wget https://raw.githubusercontent.com/elastic/elasticsearch/master/docs/src/test/resources/accounts.json
curl -H "Content-Type: application/json" -XPOST "localhost:9200/banke/_bulk?pretty&refresh" --data-binary "@accounts.json"
```

### Document 的 Metadata fields

查询的 Document 的时候会发现，返回了很多带有 `_` 前缀的 field:

```sh
GET  /my-index-000001/_doc/1

{
  "_index" : "my-index-000001",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 1,
  "_seq_no" : 0,
  "_primary_term" : 1,
  "found" : true,
  "_source" : {
    "age" : 11,
    "email" : "xiaomang@mail.com",
    "name" : "小王"
  }
}
```

ES 支持的 [Metadata fields][8] ：

```sh
_field_names field
_ignored field
_id field
_index field
_meta field
_routing field
_source field
_type field
```


### field 数值类型汇总

field 可以使用以下数据类型， 不同版本的支持情况可能不同，详情见 [Field data types][7]：

**常规类型：**

1. binary
2. boolean
3. keywords：keyword/constan_keyword/wildcard
4. numbers：long/integer/short/byte/double/float/halt_float/scaled_float/unsigned_long
5. dates：date/date_nanos
6. alias：用于定义别名

**对象类型：**

1. object：json对象可以被自动mapping
2. flattened：值为 json 类型的 field
3. nested
4. join

**结构化类型：**

1. range：integer_range/float_range/long_range/double_range/date_range/ip_range
2. ip：ip地址
3. version：https://semver.org/ 类型的版本号
4. murmur3：一个插件，用于生成 field 的哈希值

**聚合数据类型：**

1. aggregate_metric_double
2. histogram

**搜索文本类型**：

1. text fields：text/match_only_text
2. annotated-text：插件
3. completion
4. search_as_you_type
5. token_count

**文档排名类型**：

1. dense_vector
2. sparse_evctor
3. rank_feature
4. rank_features

**地理位置类型**：

1. geo_point
2. geo_shape
3. point
4. shape

**其它类型**：

1. percolator

**数组类型不需要专门定义，每个 filed 的数值都可以是一个数组列表。**

一个 field 可以有多个类型，以用于不同目的，这个特性叫做 [multi-fields][22]。

如下所示，city field 有两个类型，分别是 text 和 keyword：

```sh
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "city": {
        "type": "text",     <-- 第一个类型 text
        "fields": {         
          "raw": {          <-- 在 fields 属性中设置一个使用其它类型的 field，名为 raw，类型为 keyword
            "type":  "keyword"   
          }
        }
      }
    }
  }
}
```

上面定义的 keyword 类型 field 的引用方法是 `city.raw`，在一次查询中可以分别用 city 和 city.raw：

```sh
GET my-index-000001/_search
{
  "query": {
    "match": {
      "city": "york" 
    }
  },
  "sort": {
    "city.raw": "asc" 
  },
  "aggs": {
    "Cities": {
      "terms": {
        "field": "city.raw" 
      }
    }
  }
}
```


### field 的配置项汇总 

Mapping 中的 field 不只可以配置 `type` ，还有很多可配置项，譬如下的 `index`：

```sh
# 为已有的 Index 增加属性设置，`_mapping`：
PUT /my-index-000001/_mapping
{
  "properties": {
    "employee-id": {
      "type": "keyword",
      "index": false         <-- false，不为 employee-id 创建索引
    }
  }
}
```

下面是 field 的配置项列表， 不同版本支持的情况可能不同，见 [Mapping Parameters][6]：

```sh
analyzer
boost
coerce
copy_to
doc_values
dynamic
eager_global_ordinals
enabled
fielddata
fields   <-- 前面设置多个类型时使用的 fields
format
ignore_above
ignore_malformed
index_options
index_phrases
index_prefixes
index
meta
normalizer
norms
null_value
position_increment_gap
properties
search_analyzer
similarity
store
term_vector
```


## 查询语法：Query 

这里用 kibana 提供的 Dev Tools， 通过 es 的 http 接口查询。ES query 语法见 [ES Query DSL][9]。

ES 根据查询语句对所有 Document 进行相关性评分，查询结果按照评分从高到低排列。

结果中的 \_score 是每个文档的得分，最高分是 1.0：

```json
{
  "took" : 254,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 2,
      "relation" : "eq"
    },
    "max_score" : 1.0,         <-- 结果中的最高分
    "hits" : [
      {
        "_index" : "my-index-000001",
        "_type" : "_doc",
        "_id" : "1",
        "_score" : 1.0,        <-- 相关性评分 
        "_source" : {
          "age" : 11,
          "email" : "xiaomang@mail.com",
          "name" : "小王"
        }
      },
      {
        "_index" : "my-index-000001",
        "_type" : "_doc",
        "_id" : "2",
        "_score" : 1.0,
        "_source" : {
          "age" : 11,
          "email" : "xiaoming@mail.com",
          "name" : "小明"
        }
      }
    ]
  }
}
```

### 查询语句结构

查询语句分为`叶子语句`（Leaf query clauses）和`组合语句`（Compound query clauses）。

**叶子语句**：针对单个 field 的查询，样式为某个 field 的数值满足 xx 条件，譬如 match 语句。

```sh
GET /banke/_search
{
  "query": { "match": { "address": "mill lane" } }
}
```

**组合语句**：是叶子语句或组合语句的组合，一次请求中给出了多个数值要求，譬如 bool 语句。

```sh
POST _search
{
  "query": {
    "bool" : {
      "must" : {
        "term" : { "user.id" : "kimchy" }
      },
      "filter": {
        "term" : { "tags" : "production" }
      },
      "must_not" : {
        "range" : {
          "age" : { "gte" : 10, "lte" : 20 }
        }
      },
      "should" : [
        { "term" : { "tags" : "env1" } },
        { "term" : { "tags" : "deployed" } }
      ],
      "minimum_should_match" : 1,
      "boost" : 1.0
    }
  }
}
```

### 查询语句的执行上下文

ES 查询语句有 query context 和 filter context 两个执行上下文，所在上下文不同，语句用途不同。

query 中的查询语句处于 query context：

```sh
GET /banke/_search
{
  "query": { "match": { "address": "mill lane" } }    <-- 位于 query context
}
```

query 的 filter 中的查询语句处于 filter context，例如 bool 语句中的 filter ：

```sh
GET /_search
{
  "query": { 
    "bool": { 
      "must": [
        { "match": { "title":   "Search"        }},    <--  位于 query context
        { "match": { "content": "Elasticsearch" }}
      ],
      "filter": [   
        { "term":  { "status": "published" }},         <--  位于 filter context
        { "range": { "publish_date": { "gte": "2015-01-01" }}}
      ]
    }
  }
}
```

**query context**：按照语句要求对 es 中的文档进行相关性评分，选出相关性高的文档。

**filter context**：按照语句要求对查询结果进行过滤。

即 `es 的查询操作和过滤操作，使用了同一套语法`。

### 准备要查询的数据

参照 [Quick Start][39]（这个文档里有些查询语法过时了） 中的例子准备查询数据。

提交数据，自动创建 index 和 mapping：

```sh
POST logs-my_app-default/_doc
{
  "@timestamp": "2011-05-06T16:21:15.000Z",
  "event": {
    "original": "192.0.2.42 - - [06/May/2011:16:21:15 +0000] \"GET /images/bg.jpg HTTP/1.0\" 200 24736"
  }
}
```

查看 index，es 自动命名为 .ds-logs-my_app-default-000001：

```sh
GET /_cat/indices?v

... .ds-logs-my_app-default-000001 ...
```

查看 mapping，es 会自动推断其它的 field，这里只关心 @timestamp 和 event：

```sh
GET logs-my_app-default/_mapping

...
      "properties" : {
        "@timestamp" : {
          "type" : "date"
        },

        "event" : {
          "properties" : {
            "original" : {
              "type" : "keyword",
              "ignore_above" : 1024
            }
          }
        },
...
```

批量写入数据：

```sh
# 注意 ：create 下面的要插入的数据不能分行
PUT logs-my_app-default/_bulk
{ "create": { } }
{ "@timestamp": "2012-05-07T16:24:32.000Z", "event": { "original": "192.0.2.242 - - [07/May/2012:16:24:32 -0500] \"GET /images/hm_nbg.jpg HTTP/1.0\" 304 0" }, "message": "小草偷偷地从土里钻出来，嫩嫩的，绿绿的。园子里，田野里，瞧去，一大片一大片满是的。坐着，躺着，打两个滚，踢几脚球，赛几趟跑，捉几回迷藏。风轻悄悄的，草软绵绵的。"}
{ "create": { } }
{ "@timestamp": "2013-05-08T16:25:42.000Z", "event": { "original": "192.0.2.255 - - [08/May/2013:16:25:42 +0000] \"GET /favicon.ico HTTP/1.0\" 200 3638" }, "message": "桃树、杏树、梨树，你不让我，我不让你，都开满了花赶趟儿。红的像火，粉的像霞，白的像雪。"}
{ "create": { } }
{ "client":"curl", "@timestamp": "2014-05-08T16:25:42.000Z", "event": { "original": "192.0.2.255 - - [08/May/2014:16:25:42 +0000] \"GET /favicon.ico HTTP/1.0\" 200 3638" }}
```

查看所有数据：

```sh
GET logs-my_app-default/_search
{
  "query": {
    "match_all": {}
  }
}
```

数据不再使用后，用下面的命令删除：

```sh
DELETE _data_stream/logs-my_app-default
```

### Search 接口

[Search API][40]  的 uri 是 “/index名称/_search”，方法为 GET，支持的参数见 [Search API][40] 。

这里只举一个例子，返回所有文档的 event field 的数值，按照 @timestamp 倒排序：

```sh
GET logs-my_app-default/_search
{
  "query": {
    "match_all": {}
  },
  "_source": ["event"],   <-- 返回的 field
  "sort": [
    {
      "@timestamp": {     <-- 按 timestamp 排序
        "order": "desc"
      }
    }
  ]
}
```



### 全部查询：match_all / match_none

[match_all][17] 最简单的查询语句，没有查询条件，把 es 中所有文档都查出来：

```sh
GET /_search
{
    "query": {
        "match_all": {}
    }
}
```

match_all 默认所有文档的相关性得分都是默认值 1.0， 如果要修改默认值用 boost 设置：

```sh
GET /_search
{
  "query": {
    "match_all": { "boost" : 1.2 }  <--  所有文档的相关性得分都设置为 1.2
  }
}
```

match_none 是 match_all 的取反，返回空结果：

```sh
GET /_search
{
  "query": {
    "match_none": {}
  }
}
```


### 精确查询：Term-level Queries

[term-level-queries][23] 用于对结构化数据进行精确查询，主要有以下语句：

1. exists
2. fuzzy
3. ids
4. prefix
5. range
6. regexp
7. term
8. terms
9. terms_set 
10. type
11. wildcard

#### 语句：exists

[exists][42] 查找包含指定列的文档:

```sh
## 是否存在
GET logs-my_app-default/_search
{
  "query": {
    "exists": {
      "field": "client"
    }
  }
}
```

#### 语句：fuzzy

[fuzzy][43] 查找位于字符串特定编辑距离内的

```sh
## 近似值
GET logs-my_app-default/_search
{
  "query": {
    "fuzzy": {
      "client": {
        "value": "lcur",
        "fuzziness": 2
      }
    }
  }
}

```

#### 语句：ids

[ids][44] 指定目标文档的ID：

```sh
## 按文档 id 查询
GET logs-my_app-default/_search
{
  "query": {
    "ids": {
      "values": ["OqdvxnwB7Uq2vygbUxnh","PadbxnwB7Uq2vygbxRcp"]
    }
  }
}
```

#### 语句：prefix

[prefix][45] 前缀匹配：

```sh
## 前缀匹配
GET logs-my_app-default/_search
{
  "query":{
    "prefix": {
      "client": {
        "value": "c"
      }
    }
  }
}
```

#### 语句：range

范围内使用 [range][41]，譬如查找指定时间段的数据：

```sh
## 范围查找
GET logs-my_app-default/_search
{
  "query": {
    "range": {
      "@timestamp": {
        "gte": "2012-01-01",
        "lte": "2013-01-01"
      }
    }
  }
}
```

#### 语句：regexp

[regexp][46] 正则匹配：

```sh
## 正则匹配
GET logs-my_app-default/_search
{
  "query": {
    "regexp": {
      "client": {
        "value": "c.*"
      }
    }
  }
}
```

#### 语句：term

[term][47] 用于 field 字段数值的精确匹配：

```sh
## field 值精确匹配
GET /_search
{
  "query": {
    "term": {
      "user.id": {
        "value": "kimchy",
        "boost": 1.0
      }
    }
  }
}
```

#### 语句：terms

[terms][48] 可指定多个匹配数值：

```sh
## field 值匹配
GET logs-my_app-default/_search
{
  "query": {
    "terms": {
      "client": ["curl","abc"]
    }
  }
}
```

#### 语句：terms_set

TODO: [terms-set][49]：

```sh
GET /job-candidates/_search
{
  "query": {
    "terms_set": {
      "programming_languages": {
        "terms": [ "c++", "java", "php" ],
        "minimum_should_match_field": "required_matches"
      }
    }
  }
}
```

#### 语句：type

7.0 开始不建议使用，type 字段已经不建议使用：

```sh
## 类型查询
GET logs-my_app-default/_search
{
  "query": {
    "type":{
      "value": "_doc"
    }
  }
}
```

#### 语句：wildcard

[wildcard][50] 支持通配符，? 匹配一个字符，* 匹配多个字符：

```sh
## 通配符
GET logs-my_app-default/_search
{
  "query": {
    "wildcard": {
      "client": {
        "value": "c??l"
      }
    }
  }
}
```

### 全文检索：full text queries

针对 text 类型的 field，使用 [full text queries][24] ，支持以下语句：

1. intervals
2. match
3. match_bool_prefix
4. match_phrase
5. match_phrase_prefix
6. multi_match
7. combined_fields
8. query_string
9. simple_query_string

#### 语句：match

[match][11] 可以用于多种类型，text/numbers/date/boolean。

```sh
GET logs-my_app-default/_search
{
  "query":{
    "match": {
      "message": "春天"
    }
  }
}
```

### 组合查询：Compound queries

查询条件不止一个时，用 [Compound queries][25] 进行组合，支持以下语句：

1. bool
2. boosting
3. constant_score
4. dis_max
5. function_score

#### 语句：bool 

组合多个子查询语句，子查询语句的组合条件可以是 must、filter、should、must_not。

[ES Boolean query][12]：

```sh
POST _search
{
  "query": {
    "bool" : {
      "must" : {
        "term" : { "user.id" : "kimchy" }
      },
      "filter": {
        "term" : { "tags" : "production" }
      },
      "must_not" : {
        "range" : {
          "age" : { "gte" : 10, "lte" : 20 }
        }
      },
      "should" : [
        { "term" : { "tags" : "env1" } },
        { "term" : { "tags" : "deployed" } }
      ],
      "minimum_should_match" : 1,
      "boost" : 1.0
    }
  }
}
```

#### 语句：boosting 

降低命中特定条件的文档的评分，[ES boosting query][13]：

```sh
GET /_search
{
  "query": {
    "boosting": {
      "positive": {
        "term": {
          "text": "apple"
        }
      },
      "negative": {
        "term": {
          "text": "pie tart fruit crumble tree"
        }
      },
      "negative_boost": 0.5
    }
  }
}
```

#### 语句：constant_score

为匹配的文档设置固定的评分，[ES constant score][14]：

```sh
GET /_search
{
  "query": {
    "constant_score": {
      "filter": {
        "term": { "user.id": "kimchy" }
      },
      "boost": 1.2
    }
  }
}
```

#### 语句：dis_max

[ES Disjunction max query][15] 

#### 语句：function_score

[ES Function score query][16]


### 连接查询：Join 

es 的 [Joining queries][26] 语句提供了一定的连接查询能力：

1. nested
2. has child
3. has parent
4. parent id

### 地理查询：Geo

es 支持地理数据查询，[Geo queries][27]：

1. geo-bounding box
2. geo-distance
3. geo-polygon
4. geoshape


#### 几何查询：Shape

es 支持存放二维的几何图形，[Shape queries][28]：

1. shape

#### 无法归类的特殊查询

还有一些特殊查询无法归类， [Specialized queries][29]：

1. distance feature
2. more like this
3. percolate
4. rank feature
5. script
6. script score
7. wrapper
8. pinned query

## 聚合语法：Aggregation

如果关心的不是单个文档，而是文档的中数值的分布等数学特征，使用 [aggs][10] 语句。

```sh
GET /bank/_search
{
  "size": 0,
  "aggs": {
    "group_by_state": {
      "terms": {
        "field": "state.keyword"
      }
    }
  }
}
```

```sh
GET /bank/_search
{
  "size": 0,
  "aggs": {
    "group_by_state": {
      "terms": {
        "field": "state.keyword"
      },
      "aggs": {
        "average_balance": {
          "avg": {
            "field": "balance"
          }
        }
      }
    }
  }
}
```

```sh
GET /bank/_search
{
  "size": 0,
  "aggs": {
    "group_by_state": {
      "terms": {
        "field": "state.keyword",
        "order": {
          "average_balance": "desc"
        }
      },
      "aggs": {
        "average_balance": {
          "avg": {
            "field": "balance"
          }
        }
      }
    }
  }
}
```

## SQL 查询

[SQL查询][20]

## 参考

0. [李佶澳的博客][1]
1. [es官网文档][21]
2. [Install Kibana With Docker][2]
3. [Install Elasticsearch With Docker][3]
4. [Elastic Stack Doc][4]
5. [Running the Elastic Stack On Docker][5]

[1]: https://www.lijiaocn.com "李佶澳的博客"
[2]: https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html "Install Elasticsearch With Docker"
[3]: https://www.elastic.co/guide/en/kibana/current/docker.html "Install Kibana With Docker" 
[4]: https://www.elastic.co/guide/index.html "Elastic Stack Doc"
[5]: https://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-docker.html "Running the Elastic Stack On Docker"
[6]: https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html "Mapping Parameters"
[7]: https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html "Mapping types"
[8]: https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-fields.html "Metadata fields"
[9]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html "ES Query DSL"
[10]: https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html "ES Aggregation"
[11]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html "ES Match query"
[12]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html  "ES Boolean query"
[13]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-boosting-query.html "ES boosting query"
[14]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-constant-score-query.html "ES constant score"
[15]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-dis-max-query.html  "ES Disjunction max query"
[16]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-function-score-query.html "ES Function score query"
[17]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-all-query.html "ES match all query"
[18]: https://www.elastic.co/guide/en/elasticsearch/reference/current/term-level-queries.html "ES term level query"
[19]: https://elkguide.elasticsearch.cn/ "ELK Stack 中文指南"
[20]: https://www.elastic.co/guide/en/elasticsearch/reference/7.1/sql-syntax-select.html "SQL查询"
[21]: https://www.elastic.co/guide/index.html "es官网文档"
[22]: https://www.elastic.co/guide/en/elasticsearch/reference/current/multi-fields.html#multi-fields "multi-fields"
[23]: https://www.elastic.co/guide/en/elasticsearch/reference/current/term-level-queries.html "term-level-queries"
[24]: https://www.elastic.co/guide/en/elasticsearch/reference/current/full-text-queries.html "full text queries"
[25]: https://www.elastic.co/guide/en/elasticsearch/reference/current/compound-queries.html "Compound queries"
[26]: https://www.elastic.co/guide/en/elasticsearch/reference/current/joining-queries.html "Joining queries"
[27]: https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-queries.html "Geo queries"
[28]: https://www.elastic.co/guide/en/elasticsearch/reference/current/shape-queries.html "Shape queries"
[29]: https://www.elastic.co/guide/en/elasticsearch/reference/current/specialized-queries.html "Specialized queries"
[30]: https://www.elastic.co/guide/en/elasticsearch/reference/current/high-availability.html "Set up a cluster for high availability"
[31]: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html "Node roles"
[32]: https://www.elastic.co/guide/en/elasticsearch/reference/current/scalability.html "Scalability and resilience: clusters, nodes, and shards"
[33]: https://www.elastic.co/cn/elasticon/conf/2016/sf/quantitative-cluster-sizing "testing with your own data and queries."
[34]: https://www.elastic.co/guide/en/elasticsearch/reference/current/xpack-ccr.html "Cross-cluster replication"
[35]: https://www.elastic.co/guide/en/elasticsearch/reference/current/high-availability-cluster-design.html "Designing for resilience"
[36]: https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html "Reading and Writing documents"
[37]: https://www.microsoft.com/en-us/research/wp-content/uploads/2008/02/tr-2008-25.pdf "PacificA: Replication in Log-Based Distributed Storage Systems"
[38]: https://www.elastic.co/guide/en/elasticsearch/reference/current/search-shard-routing.html#search-adaptive-replica "Adaptive replica selection"
[39]: https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html "Quick Start"
[40]: https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html "Search API"
[41]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-query.html "range"
[42]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-exists-query.html "exists"
[43]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-fuzzy-query.html "fuzzy"
[44]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-ids-query.html "ids"
[45]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-prefix-query.html "prefix"
[46]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-regexp-query.html "regexp"
[47]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-term-query.html "term"
[48]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-terms-query.html "terms"
[49]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-terms-set-query.html "terms-set"
[50]: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-wildcard-query.html "wildcard"
